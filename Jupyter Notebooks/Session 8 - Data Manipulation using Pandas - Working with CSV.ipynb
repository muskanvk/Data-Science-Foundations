{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day14 - Data Manipulation using Pandas - Part2 - Working with CSV\n",
    "\n",
    "- Pandas is an open-source Python Library providing high-performance data manipulation and analysis tool using its powerful data structures.\n",
    "\n",
    "\n",
    "\n",
    "##### Note: \n",
    "1. First Clean the Evironment (Go to \"Kernel\" Menu --> \"Restart & Clean Output\"\n",
    "2. To execute the code --> Click on a cell and press cntrl + enter key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Features of Pandas\n",
    "- Fast and efficient DataFrame object with default and customized indexing.\n",
    "- Tools for loading data into in-memory data objects from different file formats.\n",
    "- Data alignment and integrated handling of missing data.\n",
    "- Reshaping and pivoting of date sets.\n",
    "- Label-based slicing, indexing and subsetting of large data sets.\n",
    "- Columns from a data structure can be deleted or inserted.\n",
    "- Group by data for aggregation and transformations.\n",
    "- High performance merging and joining of data.\n",
    "- Time Series functionality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Working with data file (csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "print(\"type(df)-->\",type(df))\n",
    "\n",
    "df.head()  #shows top five rows of the dataset\n",
    "\n",
    "# Try Also\n",
    "#print (\"\\n\",df.head())   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Read Excel file --> pd.read_excel()\n",
    "# To Read Json  file --> pd.read_json()\n",
    "# To Read HTML  file --> pd.read_html()\n",
    "\n",
    "# Self learning: How to read data from SQL, MongoDB, Oracle, MySQL using python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Get the dimension of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df.size -->\", df.size)\n",
    "print(\"df.ndim -->\", df.ndim)\n",
    "print(\"df.shape -->\", df.shape)\n",
    "print(\"Rows     -->\", df.shape[0])\n",
    "print(\"Columns  -->\", df.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Show top 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "# Try Also\n",
    "#df.head(10)\n",
    "#df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Show bottom 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()\n",
    "\n",
    "# Try Also\n",
    "#df.tail(10)\n",
    "#df.tail(20)\n",
    "\n",
    "\n",
    "# Question: Select rowz from 51 to 60\n",
    "# Answer: df.head(61).tail(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Get all column names of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "\n",
    "# Try Also\n",
    "#len(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Get the statistical summary of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Get the information related to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "#df.columns    #Displays the column names\n",
    "\n",
    "#df.T          #Transposes the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Transposing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 Accessing data from dataset - Part 1 (using loc - Column Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax --> loc[ ROW, COL_Names_in_List ]\n",
    "\n",
    "df.loc[:, ['F1','F3','F6']].head()\n",
    "\n",
    "# Also Try\n",
    "#df.loc[10: , ['F1','F3','F6']]\n",
    "#df.loc[10:100 , ['F1','F3','F6','F7']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.10 Accessing data from dataset - Part 2 (using iloc - Column position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Syntax --> iloc[ ROW, COL_Position]\n",
    "\n",
    "df.iloc[0:10, :5]\n",
    "\n",
    "# Also Try\n",
    "#df.iloc[10:100, :-2]\n",
    "#df.iloc[20:30, 1:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.11 To get unique values in a Column (factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['F1'].unique()\n",
    "\n",
    "#len(df['F1'].unique())\n",
    "\n",
    "#df['F4'].unique()\n",
    "\n",
    "#len(df['F4'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.10 To get unique count  in a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['F1'].value_counts()\n",
    "\n",
    "#df['F5'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.11 Selecting data using condition - part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['F4']>10]\n",
    "\n",
    "#df[df['F4']>10].shape\n",
    "\n",
    "#df[(df['F4']>20) & (df['F1'] == 1)].shape\n",
    "\n",
    "#df[(df['F4']>20) | (df['F1'] == 1)].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.12 Selecting data using condition - part 2 (using loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['F4']>20) & (df['F1'] == 1)]\n",
    "\n",
    "#df.loc[(df['F4']>20) & (df['F1'] == 1)].shape\n",
    "\n",
    "#df.loc[(df['F4']>10) | (df['F1'] == 0)].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.13 Selecting data using condition - part 3 (using query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('F4 > 20  & F1 == 1')\n",
    "\n",
    "#df.query('F4 > 20  & F1 == 1').shape\n",
    "\n",
    "#df.query('F4 > 10  | F1 == 0').shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.14 Selecting data using condition - part 4 (using eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.eval('F4 > 20  & F1 == 1')]\n",
    "\n",
    "#df[df.eval('F4 > 20  & F1 == 1')].shape\n",
    "\n",
    "#df[df.eval('F4 > 10  | F1 == 0')].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.15 Get the mean of the all the columns present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()\n",
    "\n",
    "# What is the output?\n",
    "df.head(50).mean()\n",
    "#df.tail(50).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.16 Get the correlation of the all the columns present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()\n",
    "\n",
    "# Note\n",
    "# 1. Shows the relationship between two objects (or data columns)\n",
    "# 2. Correlation value lies between -1 and +1\n",
    "# 3. If correlation of two columns (Features) is greater than 0.8 (or 0.85 or 0.9), \n",
    "#    then we can drop one of the column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.17 Get the maximum of each column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.18 Get the minimum of each column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.19 Get the median of each column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.20 Get the standard deviation of each column in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.21 Append the dataset with the same dataset (make the vaules duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df.shape      -->\",df.shape)\n",
    "\n",
    "temp_df = df.append(df)\n",
    "\n",
    "print(\"temp_df.shape -->\",temp_df.shape)\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.22 Drop the duplicates present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df.shape      -->\", df.shape , \"Before\")\n",
    "print(df)\n",
    "temp_df = df.drop_duplicates()\n",
    "print(\"\")\n",
    "print(\"temp_df.shape -->\",temp_df.shape, \" After droping duplicates\")\n",
    "print(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.23 IsNull: This returns true or false depending on the status of the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()\n",
    "\n",
    "# Shows True where NULL are present else False \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.24 Aggregate of all the values which are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.25 Drop NA values (delete rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new sample dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\"Name\":[\"Iron-Man\",\"Wonder-Woman\",\"Avengers\",\"Ramayan\"],\n",
    "                     \"House\":[\"Marvel\",\"DC Comics\",\"Marvel\",\"Ramanand Sagar\"],\n",
    "                     \"Salary\":[np.nan, 5000, \n",
    "                              np.NaN, 2000]})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()     # Drop those rows having any \"NA\"\n",
    "                # But, No change in the original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.26 Drop the columns where there are null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.27 Drop the entire row and column if ALL THE VALUES are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.28 Drop the null values where they are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how = 'any') # Similar to df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.29 Fill the null values with '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame([[3,np.nan,4,2],[5,2,np.nan,9],\n",
    "                       [np.nan,np.nan,7,np.nan],\n",
    "                       [4,np.nan,5,np.nan]],\n",
    "                        columns=list('PQRS'))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0)             # Fill ALL \"NA\" value to \"0\"\n",
    "\n",
    "# Try also: To save in the dataset\n",
    "#df.fillna(0, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.30 Replace Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame([[3,np.nan,4,2],[5,2,np.nan,9],\n",
    "                       [np.nan,np.nan,7,np.nan],\n",
    "                       [4,np.nan,5,np.nan]],\n",
    "                        columns=list('PQRS'))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the values columnwise\n",
    "replaceValues = {'P':10,'Q':11,'R':12,'S':13}  \n",
    "\n",
    "df.fillna(replaceValues, limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.31 Fill null values only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(replaceValues, limit = 1)  # Replace first NA value in every column\n",
    "\n",
    "# Try Also\n",
    "# Replace first two NA value in every column and save\n",
    "#df.fillna(replaceValues, limit = 2)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.32 Calculated the mean of column (ignore NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['P'].mean()       # Find the mean of column 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()            # Find the mean of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,[1,2]].mean()            # Find the mean of 1 and 2 column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.33 Filled the missing values with the calculated mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA values in one columns with its \"column mean\"\n",
    "mean1 = df['P'].mean()\n",
    "print(mean1)\n",
    "df['P'].fillna(mean1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA values in all columns with \"column mean\"\n",
    "df.fillna(df.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.35 Fill the missing values with the mean of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in the dataset\n",
    "df.fillna(df.mean(), inplace= True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.36 Find the correlation between all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.37 Saving dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Test.csv\")\n",
    "\n",
    "# Open Test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.38 Converting dataframe to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
